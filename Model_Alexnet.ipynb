{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Alexnet** Model  \n",
    "5 Conv Layers,1 Flatten, 2 Fully Connected, Output Layer\n",
    "\n",
    "**First Layer:**\n",
    "The input for AlexNet is a 227x227x3 RGB image which passes through the first convolutional layer with 96 feature maps or filters having size 11×11 and a stride of 4. The image dimensions changes to 55x55x96.\n",
    "Then the AlexNet applies maximum pooling layer or sub-sampling layer with a filter size 3×3 and a stride of two. The resulting image dimensions will be reduced to 27x27x96.\n",
    "\n",
    "\n",
    "\n",
    "**Second Layer:**\n",
    "Next, there is a second convolutional layer with 256 feature maps having size 5×5 and a stride of 1.\n",
    "Then there is again a maximum pooling layer with filter size 3×3 and a stride of 2. This layer is same as the second layer except it has 256 feature maps so the output will be reduced to 13x13x256.\n",
    "\n",
    "\n",
    "\n",
    "**Third, Fourth and Fifth Layers:**\n",
    "The third, fourth and fifth layers are convolutional layers with filter size 3×3 and a stride of one. The first two used 384 feature maps where the third used 256 filters.\n",
    "The three convolutional layers are followed by a maximum pooling layer with filter size 3×3, a stride of 2 and have 256 feature maps.\n",
    "\n",
    "\n",
    "\n",
    "**Sixth Layer:**\n",
    "The convolutional layer output is flatten through a fully connected layer with 9216 feature maps each of size 1×1.\n",
    "\n",
    "\n",
    "\n",
    "**Seventh and Eighth Layers:**\n",
    "Next is again two fully connected layers with 4096 units.\n",
    "\n",
    "\n",
    "\n",
    "**Output Layer:**\n",
    "Finally, there is a softmax output layer ŷ with 1000 possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if __name__=='__main__':\n",
    "    tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D,Dropout,Activation,BatchNormalization,MaxPool2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(tf.keras.Model):\n",
    "    def __init__(self,classes):\n",
    "        super(Alexnet,self).__init__()\n",
    "        \n",
    "        self.input_names = \"None\"\n",
    "        #1st Conv Layer\n",
    "        self.conv1 = Sequential()\n",
    "        self.conv1.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding='valid'))\n",
    "        self.conv1.add(Activation('relu'))\n",
    "        self.conv1.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "        self.conv1.add(BatchNormalization())\n",
    "        \n",
    "        #2nd Conv Layer\n",
    "        self.conv2 = Sequential()\n",
    "        self.conv2.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding='same'))\n",
    "        self.conv2.add(Activation('relu'))\n",
    "        self.conv2.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "        self.conv2.add(BatchNormalization())\n",
    "            \n",
    "        #3rd Conv Layer    \n",
    "        self.conv3 = Sequential()\n",
    "        self.conv3.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "        self.conv3.add(Activation('relu'))\n",
    "        self.conv3.add(BatchNormalization())\n",
    "        \n",
    "        #4th Conv Layer\n",
    "        self.conv4 = Sequential()\n",
    "        self.conv4.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "        self.conv4.add(Activation('relu'))\n",
    "        self.conv4.add(BatchNormalization())\n",
    "            \n",
    "        #5th Conv Layer    \n",
    "        self.conv5 = Sequential()\n",
    "        self.conv5.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "        self.conv5.add(Activation('relu'))\n",
    "        self.conv5.add(BatchNormalization())\n",
    "        self.conv5.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "        \n",
    "        #6th Layer  & 7th Layer\n",
    "        self.fc = Sequential()\n",
    "        self.fc.add(Flatten())\n",
    "        self.fc.add(Dense(4096))\n",
    "        self.fc.add(Activation('relu'))\n",
    "        self.fc.add(Dropout(0.4))\n",
    "        \n",
    "        #8th Layer\n",
    "        self.fc.add(Dense(4096))\n",
    "        self.fc.add(Activation('relu'))\n",
    "        self.fc.add(Dropout(0.4))\n",
    "                           \n",
    "        #9th Output Layer\n",
    "        self.classification_layer = Sequential()\n",
    "        self.classification_layer.add(Dense(classes))\n",
    "    \n",
    "    def call(self,x):\n",
    "        #print(x.shape)\n",
    "        conv1 = self.conv1(x)\n",
    "        #print(conv1.shape)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        #print(conv2.shape)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        #print(conv3.shape)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        #print(conv4.shape)\n",
    "        conv5 = self.conv5(conv4)\n",
    "        #print(conv5.shape)\n",
    "        fc = self.fc(conv5)\n",
    "        #print(fc.shape)\n",
    "        out = self.classification_layer(fc)\n",
    "        #print(out.shape)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the **Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmax_cross_entropy:\n",
    "    def __call__(self,onehot_labels,logits):\n",
    "        return tf.losses.softmax_cross_entropy(onehot_labels,logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile** your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Alexnet(classes=10)\n",
    "lr = 1e-5\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "model.compile(optimizer=optimizer,loss=softmax_cross_entropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load** Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dl.cifar10_loader(\"../../Datasets/cifar-10-batches-py/\",buffer_size=1024,batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train** the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 213.7497\n",
      "Epoch 1 Loss 155.6060\n",
      "Epoch 3 batch 55\r"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i,(x,y) in enumerate(dataset('train')):\n",
    "        epoch_loss += model.fit(x=x,y=y,epochs=1,verbose=0,batch_size=512).history['loss'][0]\n",
    "        print('Epoch %d batch %d'%(e+1,i+1),end='\\r')\n",
    "        \n",
    "    print(\"Epoch %d Loss %.4f\"%(e,epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
